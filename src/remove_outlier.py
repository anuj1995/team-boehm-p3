import numpy as np
import cv2
import os
import math
from sklearn.cluster import*
import json
import argparse
from collections import Counter


def generate_numpy(path,factor = False):
    ''' function to get the training and testing data as np array.
    arguments:
    path -- path to project directory conataining images
    '''
    x = []
    f = []
    for img in os.listdir(path):
        image = cv2.imread(path+"/"+img,0)
        if np.amax(image)>0:
            factor = (255/np.amax(image))
            image = image * factor
            x.append(image)
            f.append(factor)
    time_series_array = np.array(x)
    factor_array = np.array(f)
    if factor:
        return time_series_array,factor_array
    else:
        return time_series_array


def get_cluster_count(labels):
    ''' function to get the cluuster count after dbscan clustering.
    arguments:
    labels -- labels generated byy dbscan algorithm
    '''
    cluster_count = dict()
    for y in np.unique(labels):
        count = 0
        for i in range(len(labels)):
            if(labels[i] == y):
                count = count + 1
        cluster_count[y] = count
    return cluster_count
    #return Counter(labels)


def remove_outliers(cluster_count, shape, img, factor , data, labels,core_pts, single = False):
    ''' function to get rid of the outlier points.
    arguments:
    cluster_count -- count of each cluster generat by dbscan
    shape -- shape of each image
    factor -- factor_array generated by generate_numpy
    data -- data generated by get_all_points
    core_pts -- core points given by dbsc algorithm
    single -- if using for single image then set it to true
    labels -- labels generated byy dbscan algorithm
    '''
    if single:
        db = np.zeros((shape[0],shape[1]),dtype = int)
    else:
        db = list()
    core_pts = core_pts.tolist()
    for i in range(len(data)):
        if labels[i] != -1 :
            if single:
                db[(data[i])[0],(data[i])[1]] = img[(data[i])[0],(data[i])[1]] / factor
            else:
                db.append(img[(data[i])[0],(data[i])[1]] / factor)
    return db

def get_all_points(img, min_treshold = 0, max_treshold = 255):
    ''' function to get rid of the outlier points.
    arguments:
    img -- image np array
    min_treshold -- minimum intensity treshold
    max_treshold -- maximum intensity treshold
    '''
    all_pts = list()
    for x in range(img.shape[0]):
        for y in range(img.shape[1]):
            if img[x,y] <= max_treshold and img[x,y] > min_treshold :
                all_pts.append([x,y])
    return all_pts

def generate_dataset(ds, factor_array ,save_path):
    ''' function to generate the dataset.
    arguments:
    ds -- complete dataset in thr form of np array.
    factor_array -- factor_array generated by generate_numpy.
    save_path -- destination save path.
    '''
    for i in range(len(ds)):
        img = ds[i]
        data = np.asarray(get_all_points(img,min_treshold = 1, max_treshold = 255))
        dbsc = DBSCAN(eps = 8, min_samples = 30).fit(data)
        labels = dbsc.labels_
        core_pts = dbsc.components_
        x = get_cluster_count(labels)
        db = remove_outliers(x, (img.shape), img, factor_array[i], data ,labels, core_pts,single= True)
        cv2.imwrite(save_path + '/' + str(i) + '.tiff',db)
        print('sample ',i)


def main(arg):
    ds, factor_array = generate_numpy(arg.test,factor = True)
    generate_dataset(ds,factor_array ,arg.save_path)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='This is CSCI8360 project 3, removeing outliers')
    parser.add_argument('-t','--test',required = True,
                help='The test dataset directory which has images folder in it')
    parser.add_argument('-s', '--save_path', default = '..',
                help = 'Path to store resulting images')
    args = parser.parse_args()
    main(args)
